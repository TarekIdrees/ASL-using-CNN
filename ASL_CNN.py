# -*- coding: utf-8 -*-
"""ASL_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M5JA5_OV0N_biYsciMnmlUvrAor8Yx_u

**Set up colab for ASL data from kaggel**
"""

! pip install kaggle

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download grassknoted/asl-alphabet

! unzip asl-alphabet.zip

"""**Import needed libraries**"""

import numpy as np
import os
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split, GridSearchCV
import cv2
import keras
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization,Activation,MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras import regularizers
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

train_dir = 'asl_alphabet_train//asl_alphabet_train'
test_dir = 'asl_alphabet_test//asl_alphabet_test'
labels_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11,
               'M': 12,
               'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23,
               'Y': 24,
               'Z': 25, 'space': 26, 'del': 27, 'nothing': 28}

def load_train_data():
    Y_train = []
    X_train = []
    size = 64, 64
    #number_of_images_per_folder = 0
    images_per_folder = 0
    print("LOADING DATA FROM : ", end="")
    for folder in os.listdir(train_dir):
        print(folder, end=' | ')
        for image in os.listdir(train_dir + "/" + folder):
            if images_per_folder == 2000:
              images_per_folder = 0
              break
            # read image
            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)
            # resize image
            temp_img = cv2.resize(temp_img, size)
            #load converted classes
            Y_train.append(labels_dict[folder])
            X_train.append(temp_img)
            images_per_folder  = images_per_folder +1
    #convert X_train to numpy
    X_train = np.array(X_train)
    #normalize the pixels of X_train
    X_train = X_train.astype('float32')/255.0
    #convert Y_train to numpy
    Y_train = np.array(Y_train)
    print()
    print('Loaded', len(X_train), 'images for training,', 'Train data shape =', X_train.shape)

    return X_train, Y_train

def load_test_data():
    labels = []
    X_test = []
    size = 64, 64
    for image in os.listdir(test_dir):
        # read image
        temp_img = cv2.imread(test_dir + '/'+ image)
        # resize image
        temp_img = cv2.resize(temp_img, size)
        # load converted classes
        labels.append(labels_dict[image.split('_')[0]])
        X_test.append(temp_img)
    #convert X_test to numpy
    X_test = np.array(X_test)
    #normalize pixels of X_test
    X_test = X_test.astype('float32')/255.0
    #convert Y_test to numpy
    Y_test = np.array(labels)
    print('Loaded', len(X_test), 'images for testing,', 'Test data shape =', X_test.shape)

    return X_test, Y_test

"""**Load data with Gray**"""

X_train, Y_train =  load_train_data()

X_test, Y_test = load_test_data()

"""**Create first CNN model**

"""

def create_model():
    
    model = Sequential()
    
    model.add(Conv2D(16, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (64,64,3)))
    model.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))
    model.add(MaxPool2D(pool_size = [3,3]))
    
    model.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))
    model.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu'))
    model.add(MaxPool2D(pool_size = [3,3]))

    model.add(Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (64,64,3)))
    model.add(Conv2D(256, kernel_size = [3,3], padding = 'same', activation = 'relu'))
    model.add(MaxPool2D(pool_size = [3,3]))
    model.add(BatchNormalization())
    model.add(Flatten())
    
    model.add(Dropout(rate = 0.5))
    model.add(Dense(512, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)))
    model.add(Dense(29, activation = 'softmax'))
    model.summary()   
    return model

"""**Crete second CNN model**"""

def create_model_2():
     model = Sequential()
     model.add(Conv2D(32, (5, 5), input_shape=(64, 64, 3)))
     model.add(Activation('relu'))
     model.add(MaxPooling2D((2, 2)))

     model.add(Conv2D(64, (3, 3)))
     model.add(Activation('relu'))
     model.add(MaxPooling2D((2, 2)))

     model.add(Conv2D(64, (3, 3)))
     model.add(Activation('relu'))
     model.add(MaxPooling2D((2, 2)))
     model.add(BatchNormalization())
     model.add(Flatten())

     model.add(Dense(128, activation='relu'))

     model.add(Dense(29, activation='softmax'))

     model.summary()
     return model

"""**Description of model 2**"""

model_2 = create_model_2()

"""**Description of model 1**"""

model = create_model()

"""**Compile fisrt model**"""

model.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])

"""**Compile second model**"""

model_2.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])

"""**Fit first model with 5 epochs**"""

epochs = 5
ThisModel = model.fit(X_train,Y_train,epochs = epochs, batch_size=64,verbose = 1)

"""**Fit second model with 5 epochs**"""

ThisModel_2 = model_2.fit(X_train, Y_train,epochs=5,batch_size=64,verbose=1)

"""**Report accuracy of model 1**"""

modelLoss , modelAccuracy = model.evaluate(X_test,Y_test)
print('Test Loss is %d'%modelLoss)
print('Test Accuracy is %d'%modelAccuracy)

"""**Report accuracy of model 2**"""

modelLoss_2 , modelAccuracy_2 = model_2.evaluate(X_test,Y_test)
print('Test Loss is %d'%modelLoss_2)
print('Test Accuracy is %d'%modelAccuracy_2)

"""**Predict using first model**"""

Y_predict=model.predict(X_test) 
classes_y=np.argmax(Y_predict,axis=1)

"""**Predict using second model**"""

Y_predict_2=model_2.predict(X_test) 
classes_y_2=np.argmax(Y_predict_2,axis=1)

"""**Report accuracy,recall and precission**"""

# calculate accuracy
accuracy = accuracy_score(Y_test, classes_y)
print('Model accuracy is: ', accuracy)

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:", precision_score(Y_test, classes_y, average='micro'))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:", recall_score(Y_test, classes_y, average='micro'))

"""**Report accuracy,recall and precission**"""

# calculate accuracy
accuracy_2 = accuracy_score(Y_test, classes_y_2)
print('Model accuracy is: ', accuracy_2)

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:", precision_score(Y_test, classes_y_2, average='micro'))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:", recall_score(Y_test, classes_y_2, average='micro'))